{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493b2781-5360-4b06-89f1-deec3bc21f39",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ab6c8-a99e-4e5a-bae8-4c6a179a8d03",
   "metadata": {},
   "source": [
    "The aim of this tutorial is to develop a model of linear regression. This is a fundamental algorithm in machine learning, and one that we will build upon later on in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32b16a-c690-41b4-88fc-d34819e8267c",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Say we have a collection of labelled examples $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$, where $N$ is the size of the dataset, $\\mathbf{x}_i$ is the feature vector of sample $i$ and $y_i$ is the label of sample $i$. Linear regression aims to fit a hyperplane to the data. A hyperplane is a generalisation of a plane in high dimensions. It is impossible to visualise a hyperplane, but the maths works just fine, so bear with me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e9eb1-ba0b-452f-8726-d01ddddef9ad",
   "metadata": {},
   "source": [
    "Based on this description, is linear regression a form of supervised learning, or unsupervised learning? Run the cell below to answer:\n",
    "<span style=\"display:none\" id=\"q1\">W3sicXVlc3Rpb24iOiAiTGluZWFyIHJlZ3Jlc3Npb24gaXMgYSB0eXBlIG9mOiIsICJ0eXBlIjogIm11bHRpcGxlX2Nob2ljZSIsICJhbnN3ZXJzIjogW3siYW5zd2VyIjogIlN1cGVydmlzZWQgbGVhcm5pbmcuIiwgImNvcnJlY3QiOiB0cnVlLCAiZmVlZGJhY2siOiAiVGhhdCdzIHJpZ2h0LiBCZWNhdXNlIHRoZSBleGFtcGxlcyBhcmUgbGFiZWxsZWQsIHRoaXMgaXMgc3VwZXJ2aXNlZCBsZWFybmluZy4ifSwgeyJhbnN3ZXIiOiAiVW5zdXBlcnZpc2VkIGxlYXJuaW5nIiwgImNvcnJlY3QiOiBmYWxzZSwgImZlZWRiYWNrIjogIk5vLiBCZWNhdXNlIHRoZSBleGFtcGxlcyBhcmUgbGFiZWxsZWQsIHRoaXMgY2Fubm90IGJlIHVuc3VwZXJ2aXNlZCBsZWFybmluZy4ifV19XQ==</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ea8e2-b426-42a8-b864-0f7cc6859ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "display_quiz(\"#q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c176bd-0f42-459d-94f6-0a63cbedec67",
   "metadata": {},
   "source": [
    "Let us define the length of the feature vector, $\\mathbf{x}_i$ (for all $i$) as $D$. If $D=1$, the model will fit a line to the data (a line of best fit). If $D=2$, the model will aim to fit a plane to the data. For $D>2$, it'll be a hyperplane that is fit to the data. \n",
    "\n",
    "In general terms, the model has the following form:\n",
    "\n",
    "$$f_{\\mathbf{w},b} = \\mathbf{w} \\mathbf{x} + b$$\n",
    "\n",
    "Once the model is trained (that is appropriate values of $\\mathbf{w}$ and $b$ have been found), it can be used for predictions at new values of $\\mathbf{x}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3029524-b944-442f-b3a8-b0c7a76d4f2b",
   "metadata": {},
   "source": [
    "### Engineering example\n",
    "\n",
    "To provide a concrete engineering example, we will consider the heat transfer through a single-glazed window. A window manufacturer may be interested in training a model that can predict the rate of heat transfer, $\\dot{Q}$, for a given glass thickness, $L$, window area, $A$, and a given temperature difference across the glass, $\\Delta T$, (the difference between the inside and outside temperature). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de5c42-4359-4e08-b86e-814c5a49ab21",
   "metadata": {},
   "source": [
    "In this problem, which variables are features, and which is the label? Run the cell below to answer:\n",
    "\n",
    "<span style=\"display:none\" id=\"q2\">W3sicXVlc3Rpb24iOiAiV2hpY2ggb2YgdGhlIGZvbGxvd2luZyBhcmUgZmVhdHVyZXM6IiwgInR5cGUiOiAibWFueV9jaG9pY2UiLCAiYW5zd2VycyI6IFt7ImFuc3dlciI6ICJUaGUgdGhpY2tuZXNzIG9mIHRoZSBnbGFzcywgJEwkLiIsICJjb3JyZWN0IjogdHJ1ZX0sIHsiYW5zd2VyIjogIlRoZSB0ZW1wZXJhdHVyZSBkaWZmZXJlbmNlICRcXERlbHRhIFQkLiIsICJjb3JyZWN0IjogdHJ1ZX0sIHsiYW5zd2VyIjogIlRoZSB3aW5kb3cgYXJlYSwgJEEkLiIsICJjb3JyZWN0IjogdHJ1ZX0sIHsiYW5zd2VyIjogIlRoZSByYXRlIG9mIGhlYXQgdHJhbnNmZXIsICRcXGRvdHtRfSQuIiwgImNvcnJlY3QiOiBmYWxzZSwgImZlZWRiYWNrIjogIk5vLiBUaGlzIGlzIHRoZSBsYWJlbCJ9XX1d</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1ca5f-8165-4e1e-8d42-29a26acf8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "display_quiz(\"#q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8625e7e1-54c7-4751-95de-89464631cc3c",
   "metadata": {},
   "source": [
    "You may notice the features are the _independent_ variables of the problem, and the label is the _dependent_ variable. Features and labels is the terminology commonly used in machine learning, but there is no appreciable difference between features and independent variables, or between labels and dependent variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d479fa2e-f82c-4763-8673-8cbc1e4ccbeb",
   "metadata": {},
   "source": [
    "To keep the analysis simple, let's  consider the case where the window thickness and Area are fixed. The manufacturer is now interested in a model that can predict the rate of heat loss for a given temperature difference. Because $A$ and $L$ are fixed, this model will only work for the specific window dimension that the model is trained for. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dde9b0-23cd-4bfc-ace6-668098ad0df5",
   "metadata": {},
   "source": [
    "We have some data in the file \"window_heat.csv\". You can see this file in the file explorer (usually to the left). We can also load it in to this notebook by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ed6172-cc25-47df-91bd-ee8ece8adae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 #Pandas is a library in Python we can use for loading csv files (amongst other things)\n",
    "df = pd.read_csv('window_heat.csv') #here, we load the csv file into a Pandas dataframe object called 'df'\n",
    "df                                  #this line causes the notebook to print out the dataframe so we can see its contents below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aeea73-0bb5-4b4d-8635-72415e739d27",
   "metadata": {},
   "source": [
    "The dataframe contains a column of temperature differences and the corresponding measured rate of heat transfer through the window. \n",
    "Try answering the following:\n",
    "\n",
    "<span style=\"display:none\" id=\"q3\">W3sicXVlc3Rpb24iOiAiSW4gdGhpcyBleGFtcGxlLCB3aGljaCBvZiB0aGUgZm9sbG93aW5nIGFyZSB0cnVlOiIsICJ0eXBlIjogIm1hbnlfY2hvaWNlIiwgImFuc3dlcnMiOiBbeyJhbnN3ZXIiOiAiRD0xLiIsICJjb3JyZWN0IjogdHJ1ZSwgImZlZWRiYWNrIjogIlRoYXQncyByaWdodC4ifSwgeyJhbnN3ZXIiOiAiRD0yLiIsICJjb3JyZWN0IjogZmFsc2UsICJmZWVkYmFjayI6ICJObywgdGhlIGxlbmd0aCBvZiB0aGUgZmVhdHVyZSB2ZWN0b3IgaXMgMSAodGhlIHRlbXBlcmF0dXJlIGRpZmZlcmVuY2UgaXMgdGhlIG9ubHkgZmVhdHVyZSkuICRcXGRvdHtRfSQgaXMgdGhlIGxhYmVsLiJ9LCB7ImFuc3dlciI6ICJOPTEiLCAiY29ycmVjdCI6IGZhbHNlLCAiZmVlZGJhY2siOiAiTm8uIFRoZSBudW1iZXIgb2YgZGF0YSBzYW1wbGVzIGlzIGdyZWF0ZXIgdGhhbiBvbmUuIn0sIHsiYW5zd2VyIjogIk49MjQiLCAiY29ycmVjdCI6IHRydWUsICJmZWVkYmFjayI6ICJZdXAsIHRoZXJlIGFyZSAyNCBkYXRhIHNhbXBsZXMgb3Igb2JzZXJ2YXRpb25zLiJ9LCB7ImFuc3dlciI6ICJOPTIzIiwgImNvcnJlY3QiOiBmYWxzZSwgImZlZWRiYWNrIjogIk5vdCBxdWl0ZSwgdGhlcmUgYXJlIDI0IGRhdGEgc2FtcGxlcyBvciBvYnNlcnZhdGlvbnMgYmVjYXVzZSB0aGUgbGlzdCBzdGFydHMgZnJvbSAwLiJ9XX1d</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7dc4b-aa86-4dfe-b286-a0d9d1c7bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "display_quiz(\"#q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238493b8-777d-4bf0-b6f9-be2f7a528862",
   "metadata": {},
   "source": [
    " We can plot the data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0f5e1-e11f-4a4e-8917-c2608961aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt         #matplotlib is a plotting library in Python\n",
    "df.plot.scatter(x='dT[C]', y='Qdot[W]')       #We plot the dataframe as a scatter plot to visualise the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bc56cf-0f9f-4534-ada6-6451e6773066",
   "metadata": {},
   "source": [
    "As expected, the rate of heat loss in Watts is higher if the temperature difference between the inside and outside is greater. We can visually see the relationship is broadly a linear one. Our aim here is to fit a line to this data through linear regression.\n",
    "\n",
    "First, we can get the raw data in numpy arrays to allow simple manipulation later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3e848-00f3-4714-bb20-5eeacfcd85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dT   = df['dT[C]'].to_numpy()\n",
    "Qdot = df['Qdot[W]'].to_numpy()\n",
    "\n",
    "print(\"Temperature Numpy array: \\n\", dT)\n",
    "print(\"Rate of heat loss Numpy array: \\n\", Qdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ed409-fbb8-43be-b3f6-21aca5f9e983",
   "metadata": {},
   "source": [
    "#### Loss Function\n",
    "\n",
    "In linear regression, we are trying to find the values of $w$ and $b$ that fit the data as best we can. To this end, we need a way of assessing how far the current values are.\n",
    "\n",
    "Our model (for D=1) has the form $f=wx+b$. We do not know what the optimal values for $w$ or $b$. For each data point, we can measure the mean of the square of the difference between the model's prediction $wx+b$ and the label:\n",
    "\n",
    "$$\\frac{1}{N} \\sum_{i=1}^N(y_i - (wx_i+b))^2$$\n",
    "\n",
    "If this is small, then the model is working well; conversely, if this is large, the model's prediction will be far from the labelled values at the known data points. We call this a loss function<a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1). We want to make the loss function as small as we can.\n",
    "\n",
    "Let's denote the loss function as $l$:\n",
    "\n",
    "$$l \\equiv \\frac{1}{N} \\sum_{i=1}^N(y_i - (wx_i+b))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3cf5eb-ca2e-4d63-b869-da1a8fd3e044",
   "metadata": {},
   "source": [
    "#### Gradient descent\n",
    "We are interested in finding the values of $w$ and $b$ that minimise $l$. We can find the partial derivatives of the loss function with respect to the parameters $w$ and $b$. This will tell us how we might expect $l$ to change with a change in $w$ or $b$.\n",
    "\n",
    "$$\\frac{\\partial l}{\\partial w} = \\frac{1}{N} \\sum_{i=1}^N -2x_i(y_i - (wx_i+b))$$,\n",
    "$$\\frac{\\partial l}{\\partial b} = \\frac{1}{N} \\sum_{i=1}^N -2(y_i - (wx_i+b))$$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d094052e-5e55-454f-90f4-115c16f3e68c",
   "metadata": {},
   "source": [
    "With these partial derivatives, we can update $w$ and $b$ to drive down the loss: \n",
    "\n",
    "$$w \\leftarrow w - \\alpha \\frac{\\partial l}{\\partial w}$$\n",
    "$$b \\leftarrow b - \\alpha \\frac{\\partial l}{\\partial b}$$\n",
    "\n",
    "where $\\alpha$ is the learning rate, and controls how quick the update is applied. Our updates for $w$ and $b$ can be implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838ad9d-6d02-4f57-a650-0d318a9a657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_wb( x, y, w, b, alpha ):\n",
    "    \"\"\"\n",
    "    Updates w and b in an attempt to reduce loss.\n",
    "\n",
    "    x: feature (in this case, x=dT, the temperature difference). \n",
    "    y: label (in this case, Qdot).\n",
    "    w: The current value of w before its update. \n",
    "    b: The current value of b before its update.\n",
    "    alpha: the learning rate.|\n",
    "    \"\"\"\n",
    "    dl_dw = 0.0                                #initialse to zero\n",
    "    dl_db = 0.0                                #initialse to zero\n",
    "\n",
    "    #find the partial derivatives:\n",
    "    for i in range(len(x)):                   #loop from i=0 to 23.\n",
    "        dl_dw += -2.0*x[i]*(y[i]-(w*x[i]+b))\n",
    "        dl_db += -2.0*(y[i]-(w*x[i]+b))\n",
    "\n",
    "    dl_dw = dl_dw/float(len(x))\n",
    "    dl_db = dl_db/float(len(x))\n",
    "\n",
    "    w = w - alpha*dl_dw\n",
    "    b = b - alpha*dl_db\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa60f6-86c8-4aa8-b4b7-70e420d5e666",
   "metadata": {},
   "source": [
    "We also need a way of evaluating the loss (or cost), $l$, for a given value of $w$ and $b$, as per the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd6aa6-2135-4e81-a72b-adcc93973dbf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(x, y, w, b):\n",
    "    l=0.0\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        l += (y[i] - (w*x[i]+b))**2\n",
    "\n",
    "    l = l/float(len(x))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314ced7-ce59-4034-96db-34280e922f75",
   "metadata": {},
   "source": [
    "With the two functions above defined, we can start to train our model. We can start with a guess of $w=0$ and $b=0$. These are the parameters of our model. We also need to choose a value of $\\alpha$. For now, let's go for $\\alpha=0.0001$ (more on this later). We will keep count of how many times the full dataset has been seen by the algorithm using the `epoch` integer.\n",
    "\n",
    "<a id='training_cell'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97c53e-4bc7-4679-87b1-db40cf211f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=0.0\n",
    "b=0.0\n",
    "alpha=0.0001\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "w, b = update_wb(dT, Qdot, w, b, alpha)\n",
    "epoch += 1\n",
    "print(\"Epoch: \", epoch, \"w: \", w, \"b: \", b, \"loss: \", loss(dT, Qdot, w, b))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23cc4d8-a95d-4560-bdc3-07b2982535fb",
   "metadata": {},
   "source": [
    "OK, let's look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c408f2f-ea69-4737-9948-b8e31a4f1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dT, Qdot, marker = 'o', ls='')\n",
    "plt.plot([0,25],[b,w*25+b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68775b32-5f60-41bd-abb8-a3bf11e100fe",
   "metadata": {},
   "source": [
    "Pretty terrible! We should try more epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c5ef2-2dbd-44f5-8b80-4fa61d0742dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5): #lets try 5 more\n",
    "    w, b = update_wb(dT, Qdot, w, b, alpha)\n",
    "    epoch += 1\n",
    "    print(\"Epoch: \", epoch, \"w: \", w, \"b: \", b, \"loss: \", loss(dT, Qdot, w, b))\n",
    "\n",
    "plt.plot(dT, Qdot, marker = 'o', ls='')\n",
    "plt.plot([0,25],[b,w*25+b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a856e5-485a-4b3b-8813-64f80d859864",
   "metadata": {},
   "source": [
    "Better, but still a way to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dfaaab-369a-4ab4-8804-bc4b726f048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):  #let's try 200 more\n",
    "    w, b = update_wb(dT, Qdot, w, b, alpha)\n",
    "    epoch += 1\n",
    "    print(\"Epoch: \", epoch, \"w: \", w, \"b: \", b, \"loss: \", loss(dT, Qdot, w, b))\n",
    "\n",
    "plt.plot(dT, Qdot, marker = 'o', ls='')\n",
    "plt.plot([0,25],[b,w*25+b])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139e93f-1713-4de6-b6d1-f7804048841c",
   "metadata": {},
   "source": [
    "Looks good. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2448dfb-7c01-4c93-b23e-543c0db34b13",
   "metadata": {},
   "source": [
    "## Things to try\n",
    "\n",
    "- What happens if you go back and train with $\\alpha=0.1$ or $1\\times 10^{-5}$? Click [here](#training_cell) to return to the start of training. Change $\\alpha$ and re-run the training cells to experiment.\n",
    "- Change from gradient descent to Stochastic Gradient Descent; be careful to ensure the `epoch` integer corresponds to any $N$ samples being seen (even if the same sample is randomly chosen more than once within an epoch). (assessed)\n",
    "- Change from MSE to MAE and compare performance. Is a different learning rate needed? (assessed)\n",
    "- Prefer Matlab? Re-implement this linear regression code in matlab and play with it there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6834592-5610-4209-954e-fe4181e21a9e",
   "metadata": {},
   "source": [
    "## Linear regression with Scikit learn or Matlab\n",
    "\n",
    "It is important to note that the above is a pedagogical example. In practical applications, you would not be well advised to implement your own linear regression. For one, this is reinventing the wheel. But perhaps even more importantly, the computational performance of our simple model is unlikely to be very good (i.e. it may take a long time to run on large datasets). In matlab, you can use the `fitlm` function to return a linear regression model. In Python, you can use Scikit-learn's `linear_model.LinearRegression()` model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e8943-a9f1-4998-9792-ecea349a4643",
   "metadata": {},
   "source": [
    "#### Footnotes\n",
    "\n",
    "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1) Formally, the loss function is the loss evaluated on a single data point (i.e. without the sum, or dividing by $N$) and the above is actually the \"cost function\". However, loss and cost are often used interchangeably, so with a minor abuse of notation to adopt the common practice in the literature, we'll call this loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
